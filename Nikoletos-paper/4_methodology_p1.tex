%\vspace{-8pt}
\section{Tackling Problem 1}
\label{sec:problem-1}
%\vspace{-4pt}

Fine-tuning an ETEER pipeline based on the ground truth comprising all duplicate pairs is similar to hyperparameter fine-tuning in Machine and Deep Learning models \cite{DBLP:journals/ijon/YangS20}. The only difference is the form of the data: in the latter case, the data comes in the form of positive and negative labelled instances, which is not possible in ETEER, due to the extremely large number of pairs that arise even from relatively small datasets with few thousand entities in $\mathcal{E}_1$ and $\mathcal{E}_2$. Besides, the number of positive pairs grows linearly with respect to the number of given entities, while all other pairs are negative, with their number growing quadratically \cite{DBLP:journals/pvldb/GetoorM12}. Therefore, instead of enumerating and labelling all possible pairs in the Cartesian product of $\mathcal{E}_1 \times \mathcal{E}_2$, hyperparameter fine-tuning is guided by the F1-score corresponding %to the matches generated by each 
to each parameter configuration of the ETEER pipeline to be fine-tuned. This is the only change that needs to be applied to existing algorithms for hyperparameter fine-tuning, yet they have not been applied before to Problem 1.

Typically, hyperparameter fine-tuning is carried out by \emph{sampling techniques}, which aim at optimizing the balance between effectiveness and time efficiency:  
%two goals of auto-configuration \cite{OPTUNA}: ($i$) 
their goal is to maximize efficiency by reducing the search space to the most promising subset of configuration parameters, without leaving out the ones maximizing effectiveness~\cite{OPTUNA}. 
%in the configuration strategy that
%is the process of 
%determines the (sub)set of parameters that are worth investigating \cite{OPTUNA}.
%, and ($ii$) the efficiency of performance estimation strategy, that estimates the value that a set of configurations will produce, based on learning curves, and finally determines the set of parameters that should be discarded. 
These sampling techniques are categorized into two main types: 
the \textit{relational} ones select the next set of configuration parameters based on the correlations between them, while the \textit{independent} ones disregard inter-parameter correlations.
%(ii) \textit{Independent sampling} selects the next configuration parameters regardless of correlations between them.

In this work, we consider the following state-of-the-art sampling algorithms \cite{OPTUNA}, which cover both types of sampling techniques:
%three are independent and one is relational (assume that $d$ is the dimension of the search space and $n$ is the number of finished trials): 

(1)  \emph{RandomSampler} \cite{QMCSampler}. As its name suggests,  
    %with %complexity of $O(d)$, is an independent sampling technique, where 
    hyper-parameter values are chosen randomly from the specified search space. This is an independent method that does not use any prior knowledge or adaptive mechanisms to guide the search process. Instead, it 
    %relies on randomness to 
    explores the search space in a purely stochastic manner, i.e.,
    %. Random sampling achieves high efficiency in many cases because 
    each point in the search space has an equal probability of being explored. This approach results in a uniform coverage of the search space. Even in high-dimensional spaces, random sampling is capable of identifying near-optimal configurations with fewer trials, especially when compared to the grid search approach. 
    %Another advantage is its high time efficiency, given that its time complexity of is $O(d n)$.

(2) Tree-structured Parzen Estimator (\emph{TPESampler}) \cite{TPE1, TPE2, TPE3}.
    %, with complexity of $O(d*n*log_2n)$, uses the TPE (Tree-structured Parzen Estimator) algorithm and utilizes independent sampling \cite{TPE1, TPE2, TPE3}. 
    During each trial for every parameter, this independent algorithm fits two Gaussian Mixture Models (GMMs): \( l(x) \) to the set of parameter values with the best objective outcomes, and \( g(x) \) to the remaining parameter values. It then selects the parameter value \( x \) that maximizes the ratio \( l(x) / g(x) \).  In other words, TPESampler models the distribution of good and bad hyperparameters using non-parametric density estimators, focusing on promising regions of the search space. By iteratively updating these models based on observed results, TPESampler may need more trials to explore potentially optimal areas, but typically exhibits better search performance than grid search and RandomSampler. 
    %, where $d$ stands for the dimensionality of the search space and $n$ for the number of completed trials. 

(3) Quasi Monte Carlo Sampler (\emph{QMCSampler}) \cite{QMCSampler}. This independent approach uses quasi-random methods, specifically low-discrepancy sequences, to enhance the efficiency of hyperparameter optimization by ensuring uniform coverage of the search space. Unlike RandomSampler, which can have uneven distribution, low-discrepancy sequences spread points more evenly, avoiding clumps and gaps. This uniformity increases the probability of finding optimal hyperparameters with fewer trials, particularly in high-dimensional settings where important dimensions need adequate sampling. 
%, where $d$ denotes the search space dimensionality and $n$ the number of executed trials.

(4) Gaussian Process-based Bayesian Sampler (\emph{GPSampler}) \cite{NIPS2012_GPSampler, QMCSampler}. This is a relational sampler that fits a Gaussian process to the objective function and optimizes the acquisition function to suggest the next set of parameters. First,
    %Bayesian optimization methods, in general, first 
    it constructs a probabilistic model of the objective function using a Gaussian process and then it exploits this model to estimate the most promising regions in the search space. 
    %The GPSampler uses a Gaussian process to represent the probabilistic distribution of the objective function, providing flexibility and adaptability. Among various acquisition functions, 
    To this end, it employs the log expected improvement 
    %(logEI) 
    in combination with QMCSampler
    %Quasi-Monte Carlo (QMC) sampling 
    to optimize the acquisition function (note that in Bayesian optimization, the acquisition function tackles the exploration-exploitation trade-off, efficiently providing numerical estimations that indicate the most promising configuration parameters to be tested \cite{DBLP:conf/nips/WilsonHD18}).
    %Gaussian process-based Bayesian approaches, have proven 
    Typically, GPSampler is highly effective in hyperparameter optimization,
    %(HPO) problems, 
    as it leverages the dependencies between hyperparameters and avoids redundant trials, due to their probabilistic estimation of the objective function \cite{NIPS2012_GPSampler, QMCSampler}. 

Regarding the time complexity \textit{per trial} of these samplers, we use $d$ for the dimensionality of the search space {(i.e., the four parameters in Table \ref{tab:parameter-values} that have to be configured in order to fine-tune the ETEER pipeline in Figure \ref{fig:eeter_pipeline})} and $n$ for the number of completed trials. The most efficient algorithm is RandomSampler, with $O(d)$, followed by QMCSampler with $O(d n )$, TPESampler with $O(d n logn)$ and GPSampler with $O(n^3)$ -- for more details, please refer to {\footnotesize \underline{https://optuna.readthedocs.io/en/stable/reference/samplers/index.html}}.

To the best of our knowledge, none of these algorithms has been applied to fine-tuning ETEER pipelines, addressing Problem 1. More specifically, each algorithm is applied to Problem 1 as follows: 
\begin{enumerate}[leftmargin=*]
    \item It receives $V$ as input, i.e., the domain of each configuration parameter, along with the maximum number of trials.
    \item In each trial, it selects a value for each configuration parameter.
    \item The resulting ETEER pipeline is applied to the given dataset to estimate its performance with respect to F1-score, using the available ground truth.
    \item After consuming the budget of trials, the configuration values $V' \subseteq V$ maximizing F1-score are returned as output.
\end{enumerate}


