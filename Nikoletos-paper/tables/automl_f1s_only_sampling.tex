\begin{table*}[t]
%{\small
\begin{center}  
\footnotesize  
\setlength{\tabcolsep}{2pt}
\caption{Performance of AutoML on Problem 2 when combined with sampling-based instances. GB stands for Gradient Boosting \cite{Friedman2001GreedyFA_GB}, KNN for K-Nearest Neighbor \cite{Fix1989DiscriminatoryA_KNN} RF for Random Forest \cite{Breiman2001RandomF_RF} and ET for Extra Trees \cite{Geurts2006ExtremelyRT_ET}. In all cases, the search/training time is 12 hours and is omitted for brevity.} 
% \vspace{-10pt}
{\small
\label{tab:autosklearn-results}
%\begin{tabular}{|c|c|l|c|c|c|p{2cm}|p{1.0cm}|p{1.0cm}|c|c|c|c|}
\begin{tabular}{|c|l|c|c|c|c|c|c|c|}
\hline
Dataset &  \multicolumn{1}{c|}{Learned ensemble} & F1 & 
%GB-F1 & F1-Ratio & 
%Optimization \& Training time (h) & 
Prediction time (s)& ETEER time (s)& LM & k & Clustering & Threshold \\
% & \multicolumn{1}{c|}{ensemble} & & 
%GB-F1 & F1-Ratio & 
%Optimization \& Training time (h) & 
%time (s) & time (s) &  &  & ering & hold \\
\hline
\hline
D1 & 0.38ET + 0.36RF + 0.14GB + 0.1KNN + 0.02GB & 55.35 & 240 & 5.84 & st5 & 1 & UMC & 0.2659 \\
D2 & 0.82ET + 0.12GB + 0.04RF + 0.02KNN & 81.94 & 179 & 0.18 & st5 & 1 & KC & 0.1722 \\
D3 & 0.54ET + 0.16ET + 0.14RF + 0.12GB + 0.04KNN & 57.79 & 218 & 2.98 & st5 & 32 & UMC & 0.05 \\
D4 & 0.5ET + 0.38RF + 0.08GB + 0.04KNN & 98.38 & 215 & 0.83 & st5 & 1 & KC & 0.05 \\
D5 & 0.78ET + 0.1GB + 0.06RF + 0.06KNN & 71.97 & 249 & 2.77 & smpnet & 1 & KC & 0.6659 \\
D6 & 0.4ET + 0.18RF + 0.18GB + 0.12GB + 0.12KNN & 55.98 & 253 & 1.23 & sminilm & 1 & KC & 0.6307 \\
D7 & 0.5ET + 0.24RF + 0.2GB + 0.04KNN + 0.02GB & 50.14 & 227 & 2.28 & smpnet & 1 & UMC & 0.228 \\
D8 & 0.52ET + 0.2RF + 0.12KNN + 0.1GB + 0.06GB & 40.77 & 230 & 20.66 & st5 & 91 & KC & 0.0501 \\
D9 & 0.52ET + 0.28RF + 0.14GB + 0.06KNN & 94.37 & 222 & 61.16 & st5 & 100 & KC & 0.4767 \\
D10 & 0.78ET + 0.12GB + 0.1ET & 36.31 & 68 & 13.65 & smpnet & 1 & KC & 0.05 \\
\hline
\end{tabular}
}
\end{center}  
\end{table*}
%Test set & Trials training set & Regressor ensembled & F1 & GB-F1 & F1-Ratio & Optimization \& Training time (h) & Prediction time (s) & ETEER Runtime (s) & LM & k & Clustering & Threshold \\
%\midrule
%D1 & sampl. & 0.38ET + 0.36RF + 0.14GB + 0.1KNN + 0.02GB & 55.35 & 78.43 & 0.71 & 12 & 240 & 5.84 & st5 & 1 & UMC & 0.265900 \\
%D2 & sampl. & 0.82ET + 0.12GB + 0.04RF + 0.02KNN & 81.94 & 85.85 & 0.95 & 12 & 179 & 0.18 & st5 & 1 & KC & 0.172200 \\
%D3 & sampl. & 0.54ET + 0.16ET + 0.14RF + 0.12GB + 0.04KNN & 57.79 & 59.19 & 0.98 & 12 & 218 & 2.98 & st5 & 32 & UMC & 0.05 \\
%D4 & all & 0.96RF + 0.04GB & 98.45 & 98.60 & 1.00 & 12 & 28 & 0.38 & st5 & 1 & CCC & 0.874200 \\
%D5 & sampl. & 0.78ET + 0.1GB + 0.06RF + 0.06KNN & 71.97 & 78.92 & 0.91 & 12 & 249 & 2.77 & smpnet & 1 & KC & 0.665900 \\
%D6 & sampl. & 0.4ET + 0.18RF + 0.18GB + 0.12GB + 0.12KNN & 55.98 & 60.42 & 0.93 & 12 & 253 & 1.23 & sminilm & 1 & KC & 0.630700 \\
%D7 & all & 0.9RF + 0.06GB + 0.04GB & 62.17 & 67.76 & 0.92 & 12 & 68 & 2.05 & st5 & 1 & UMC & 0.75 \\
%D8 & sampl. & 0.52ET + 0.2RF + 0.12KNN + 0.1GB + 0.06GB & 40.77 & 49.53 & 0.82 & 12 & 230 & 20.66 & st5 & 91 & KC & 0.050100 \\
%D9 & all & 0.94RF + 0.06GB & 94.39 & 94.92 & 0.99 & 12 & 40 & 35.18 & st5 & 92 & KC & 0.70 \\
%D10 & sampl. & 0.78ET + 0.12GB + 0.1ET & 36.31 & 56.12 & 0.65 & 12 & 68 & 13.65 & smpnet & 1 & KC & 0.05 \\